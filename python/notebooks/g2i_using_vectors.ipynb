{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sin, cos, sqrt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from the i2g_g2i collinearity noteboook\n",
    "def opk_to_rotation(o, p, k):\n",
    "    \"\"\"\n",
    "    Convert from Omega, Phi, Kappa to a 3x3 rotation matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    o : float\n",
    "        Omega in radians\n",
    "    p : float\n",
    "        Phi in radians\n",
    "    k : float\n",
    "        Kappa in radians\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "     : ndarray\n",
    "       (3,3) rotation array\n",
    "       \n",
    "    \"\"\"\n",
    "    om = np.empty((3,3))\n",
    "    om[:,0] = [1,0,0]\n",
    "    om[:,1] = [0, cos(o), -sin(o)]\n",
    "    om[:,2] = [0, sin(o), cos(o)]\n",
    "    \n",
    "    pm = np.empty((3,3))\n",
    "    pm[:,0] = [cos(p), 0, sin(p)]\n",
    "    pm[:,1] = [0,1,0]\n",
    "    pm[:,2] = [-sin(p), 0, cos(p)]\n",
    "    \n",
    "    km = np.empty((3,3))\n",
    "    km[:,0] = [cos(k), -sin(k), 0]\n",
    "    km[:,1] = [sin(k), cos(k), 0]\n",
    "    km[:,2] = [0,0,1]\n",
    "    \n",
    "    return km.dot(pm).dot(om)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignoring distortion for now (do_distort = False)\n",
    "def distort(xp, yp):\n",
    "    # Distortion creates weird values for input 100,100? Look at IK again.\n",
    "    do_distort = False\n",
    "    if not do_distort:\n",
    "        return xp, yp\n",
    "    x_coefs = [\n",
    "        0.0,\n",
    "        1.0020558791381275,\n",
    "        0.0,\n",
    "        0.0,\n",
    "        -5.448742222712919e-4,\n",
    "        0.0,\n",
    "        6.597498811862692e-6,\n",
    "        0.0,\n",
    "        6.683129056014682e-6,\n",
    "        0.0\n",
    "    ]\n",
    "    y_coefs = [\n",
    "        -1.3657975359540047e-5,\n",
    "        0.0,\n",
    "        1.0,\n",
    "        8.85544334965699e-4,\n",
    "        0.0,\n",
    "        3.338939138331483e-4,\n",
    "        0.0,\n",
    "        7.74756721313425e-6,\n",
    "        0.0,\n",
    "        7.79484564042716e-6\n",
    "    ]\n",
    "    taylor = [1, xp, yp, xp*xp, xp*yp, yp*yp, xp*xp*xp, xp*xp*yp, xp*yp*yp, yp*yp*yp]\n",
    "    distorted_x = np.dot(x_coefs, taylor)\n",
    "    distorted_y = np.dot(y_coefs, taylor)\n",
    "    return distorted_x, distorted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(v, m, inverse=False):\n",
    "    \"\"\"\n",
    "    Rotate a given 3D vector by a given rotation matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    v : list\n",
    "        3 element list representing a 3D vector\n",
    "    m : list\n",
    "        3x3 (2D list) rotation matrix to use (see opk_to_rotation)\n",
    "    inverse : bool\n",
    "        If True, will perform an inverse rotation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "     : list\n",
    "         Vector with rotation applied to it\n",
    "    \"\"\"\n",
    "    if inverse:\n",
    "        m = np.linalg.inv(m)\n",
    "    return [\n",
    "        m[0,0] * v[0] + m[0,1] * v[1] + m[0,2] * v[2],\n",
    "        m[1,0] * v[0] + m[1,1] * v[1] + m[1,2] * v[2],\n",
    "        m[2,0] * v[0] + m[2,1] * v[1] + m[2,2] * v[2]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def groundToImage(ground_point, sensor_point_b, focal_length, rotation_matrix):\n",
    "    \"\"\"\n",
    "    Given a body-fixed ground point, get the line,sample on the image.\n",
    "    Note: No error checking or intersection checking is performed.\n",
    "          TODO: Intersection check: check if returned line,sample within image dimensions.\n",
    "          \n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_point : list\n",
    "        Body-fixed XYZ coordinate of ground point on target body.\n",
    "    sensor_point_b : list\n",
    "        Body-fixed XYZ coordinate of sensor.\n",
    "    focal_length : float\n",
    "        Sensor focal length.\n",
    "    rotation_matrix : list\n",
    "        3x3 matrix (2D array) to perform rotations between body-fixed and sensor frame, and vice versa.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "     : list\n",
    "         Line, Sample value on the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTES\n",
    "    # _b suggests body-fixed coordinates\n",
    "    # _c suggests sensor frame coordinates\n",
    "    \n",
    "    # Determine the center look direction (center_x, center_y, f) of the sensor in body-fixed\n",
    "    # (e.g. the sensor's optical axis rotated into body-fixed frame)\n",
    "    sensor_optical_axis_b = rotate([0.,0.,focal_length], rotation_matrix)\n",
    "    \n",
    "    # Find the look vector from the sensor optical center to the ground point in body-fixed\n",
    "    look_ground_b = np.subtract(ground_point, sensor_point_b)\n",
    "    \n",
    "    # Normalize by scaling the sensor-to-ground look vector to the sensor optical axis body-fixed vector\n",
    "    mag = np.sqrt(np.dot(sensor_optical_axis_b, sensor_optical_axis_b))\n",
    "    mag_ground = np.sqrt(np.dot(look_ground_b, look_ground_b))\n",
    "    \n",
    "    look_ground_b = np.multiply((mag / mag_ground), look_ground_b)\n",
    "    print(\"\\tDEBUG Sensor-to-ground (body-fixed): \", look_ground_b)\n",
    "    \n",
    "    # Rotate the sensor-to-ground look vector from body-fixed to sensor frame (inverse rotation)\n",
    "    look_ground_c = rotate(look_ground_b, rotation_matrix, True)\n",
    "    print(\"\\tDEBUG Sensor-to-ground (sensor frame): \", look_ground_c)\n",
    "    \n",
    "    # Scale the sensor-to-ground sensor frame vector so that it intersects the focal plane\n",
    "    # (i.e. scale it so its Z-component equals the sensor's focal length)\n",
    "    focal_plane_coord = np.multiply(look_ground_c, (focal_length / look_ground_c[2]))\n",
    "    \n",
    "    # Distortion (**this doesn't do anything right now**)\n",
    "    distorted_x, distorted_y = distort(focal_plane_coord[0], focal_plane_coord[1])\n",
    "        \n",
    "    # Convert focal_plane mm to pixels\n",
    "    # (this would be using itrans from ISD, or inverse of trans from ISD)\n",
    "    pixels = [\n",
    "        distorted_x * (1. / 0.014),\n",
    "        distorted_y * (1. / 0.014)\n",
    "    ]\n",
    "    print(\"\\tDEBUG Pixels: \", pixels)\n",
    "    \n",
    "    # Convert pixels to line,sample\n",
    "    sample = pixels[0] + 512.0\n",
    "    line = pixels[1] + 512.0\n",
    "    \n",
    "    return line,sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groundToImage: result should be around 512,512\n",
      "\n",
      "\tDEBUG Sensor-to-ground (body-fixed):  [-330.30872618  269.63913713 -346.00760233]\n",
      "\tDEBUG Sensor-to-ground (sensor frame):  [0.0021944163992770882, -0.0016542996706334634, 549.1178195303936]\n",
      "\tDEBUG Pixels:  [0.15674402852175495, -0.11816426218958431]\n",
      "\n",
      "RESULT:  (511.88183573781043, 512.15674402852176)\n",
      "\n",
      "********************************************************************************\n",
      "\n",
      "groundToImage: result should be around 100,100\n",
      "\n",
      "\tDEBUG Sensor-to-ground (body-fixed):  [-336.78799907  266.63070164 -342.07059558]\n",
      "\tDEBUG Sensor-to-ground (sensor frame):  [-5.7691080334312801, -5.7653407997259478, 549.05724471254155]\n",
      "\tDEBUG Pixels:  [-412.12460793998889, -411.8554901309912]\n",
      "\n",
      "RESULT:  (100.1445098690088, 99.875392060011109)\n"
     ]
    }
   ],
   "source": [
    "# tests/data/EN1007907102M.cub/json image ISD\n",
    "XL = 1728357.70312\n",
    "YL = -2088409.0061\n",
    "ZL = 2082873.92806\n",
    "\n",
    "o = 2.25613094079\n",
    "p = 0.094332016311\n",
    "k = -0.963037547862\n",
    "\n",
    "f = 549.1178195372703\n",
    "pixel_pitch = 0.014 # transX/transY\n",
    "\n",
    "# Compute the rotation matrix to use from omega, phi, kappa\n",
    "M = opk_to_rotation(o,p,k)\n",
    "\n",
    "# 512, 512 (distortion irrelevant as this is the center of the image)\n",
    "print(\"groundToImage: result should be around 512,512\")\n",
    "X =  1129210.\n",
    "Y = -1599310.\n",
    "Z =  1455250.\n",
    "print()\n",
    "print(\"\\nRESULT: \", groundToImage([X,Y,Z], [XL, YL, ZL], f, M))\n",
    "print()\n",
    "print('*'*80)\n",
    "print()\n",
    "\n",
    "# Distorted coordinates do not work for 100,100 ?\n",
    "# X = 1121630.\n",
    "# Y = -1606590.\n",
    "# Z = 1453100.\n",
    "\n",
    "# Undistorted coordinates work for 100,100\n",
    "# -- These are obtained by turning off distortion in MdisNacSensorModel::imageToGround,\n",
    "#    make and ./runTests, then look at the non-truth output values for imageToGround1 test.\n",
    "print(\"groundToImage: result should be around 100,100\")\n",
    "uX = 1115920.\n",
    "uY = -1603550.\n",
    "uZ = 1460830.\n",
    "print()\n",
    "print(\"\\nRESULT: \", groundToImage([uX,uY,uZ], [XL, YL, ZL], f, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTES:\n",
    "# * TODO: implement a intersection check in groundToImage (just check if result is in image dimensions)\n",
    "# * TODO: fix distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
